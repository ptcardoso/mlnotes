{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "def normalize(data):\n",
    "    for row in data.T:\n",
    "        f_mean = np.mean(row)\n",
    "        f_range = np.amax(row) - np.amin(row)\n",
    "        \n",
    "        row -= f_mean\n",
    "        row /= f_range\n",
    "    return data\n",
    "\n",
    "# sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# predict by applying sigmoid to linearity\n",
    "def predict(x, weights, bias):\n",
    "    z = np.dot(x, weights) + bias\n",
    "    return sigmoid(z)\n",
    "\n",
    "# use cross entropy instead of mse (mse no appropriate to use with non-linear functions because there are many local maxima)\n",
    "def cross_entropy(y_hat, y):\n",
    "    n = y.shape[0]\n",
    "    \n",
    "    cost = np.multiply(y, np.log(y_hat))\n",
    "    cost += np.multiply((np.ones(y.shape) - y), np.log(np.ones(y.shape) - y_hat))\n",
    "    cost *= -1/n\n",
    "    \n",
    "    return cost.sum()\n",
    "\n",
    "# update weights and bias\n",
    "def update_parameters(x, y, y_hat, weights, bias, learning_rate=0.05):\n",
    "    \n",
    "    n = y.shape[0]\n",
    "    \n",
    "    error = y_hat - y\n",
    "    \n",
    "    dw = np.dot(x.T, error) / n\n",
    "    db = error.sum() / n\n",
    "    \n",
    "    weights -= dw * learning_rate\n",
    "    bias -= db * learning_rate\n",
    "\n",
    "# fit\n",
    "def train(x, y, iterations=200):\n",
    "    w = np.random.rand(x.shape[1],1)\n",
    "    b = np.ones((1,1))\n",
    "\n",
    "    for n in range(iterations):\n",
    "        y_hat = predict(x, w, b)\n",
    "        update_parameters(x, y, y_hat, w, b)\n",
    "        \n",
    "        if (n + 1) % 10 == 0:\n",
    "            print(\"%ith iteration error: %s\" % (n + 1, cross_entropy(y_hat, y)))\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10th iteration error: 0.983109897443543\n",
      "20th iteration error: 0.8821883548686467\n",
      "30th iteration error: 0.8078273764961492\n",
      "40th iteration error: 0.7530585837415128\n",
      "50th iteration error: 0.7121280992690091\n",
      "60th iteration error: 0.6807573595463496\n",
      "70th iteration error: 0.6559455619587355\n",
      "80th iteration error: 0.6356508177795513\n",
      "90th iteration error: 0.618502089594986\n",
      "100th iteration error: 0.6035818176419758\n",
      "110th iteration error: 0.5902743546650608\n",
      "120th iteration error: 0.5781641027164113\n",
      "130th iteration error: 0.5669681325892126\n",
      "140th iteration error: 0.556491831544904\n",
      "150th iteration error: 0.5465996838596947\n",
      "160th iteration error: 0.5371959483720176\n",
      "170th iteration error: 0.5282118165298113\n",
      "180th iteration error: 0.5195968317964295\n",
      "190th iteration error: 0.5113131267723322\n",
      "200th iteration error: 0.5033315344351263\n",
      "210th iteration error: 0.4956289529167728\n",
      "220th iteration error: 0.48818655297336616\n",
      "230th iteration error: 0.48098855441035787\n",
      "240th iteration error: 0.4740213880133503\n",
      "250th iteration error: 0.4672731194200185\n",
      "260th iteration error: 0.4607330513555724\n",
      "270th iteration error: 0.454391447512715\n",
      "280th iteration error: 0.44823933948848305\n",
      "290th iteration error: 0.442268390480798\n",
      "300th iteration error: 0.43647079780539916\n",
      "310th iteration error: 0.4308392219908045\n",
      "320th iteration error: 0.42536673409825265\n",
      "330th iteration error: 0.4200467755710521\n",
      "340th iteration error: 0.414873126733893\n",
      "350th iteration error: 0.40983988130331833\n",
      "360th iteration error: 0.4049414251172384\n",
      "370th iteration error: 0.40017241786831914\n",
      "380th iteration error: 0.39552777701842556\n",
      "390th iteration error: 0.3910026633374142\n",
      "400th iteration error: 0.38659246768949923\n",
      "[[0.14833713]\n",
      " [0.29138812]\n",
      " [0.30477661]\n",
      " [0.50859845]]\n"
     ]
    }
   ],
   "source": [
    "w = np.random.rand(2,1)\n",
    "b = np.ones((1,1))\n",
    "x = np.array([[0, 0], [1, 0], [0, 1], [1, 1]])\n",
    "y = np.array([[0], [0], [0], [1]])\n",
    "\n",
    "w, b = train(x, y, 400)\n",
    "\n",
    "y_hat = predict(x, w, b)\n",
    "print(y_hat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
