{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "def normalize(data):\n",
    "    for row in data.T:\n",
    "        f_mean = np.mean(row)\n",
    "        f_range = np.amax(row) - np.amin(row)\n",
    "        \n",
    "        row -= f_mean\n",
    "        row /= f_range\n",
    "    return data\n",
    "\n",
    "# sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# predict by applying sigmoid to linearity\n",
    "def predict(x, weights, bias):\n",
    "    z = np.dot(x, weights) + bias\n",
    "    return sigmoid(z)\n",
    "\n",
    "# use cross entropy instead of mse (mse no appropriate to use with non-linear functions because there are many local maxima)\n",
    "def cross_entropy(y_hat, y):\n",
    "    n = y.shape[0]\n",
    "    \n",
    "    cost = np.multiply(y, np.log(y_hat))\n",
    "    cost += np.multiply((np.ones(y.shape) - y), np.log(np.ones(y.shape) - y_hat))\n",
    "    cost *= -1/n\n",
    "    \n",
    "    return cost.sum()\n",
    "\n",
    "# update weights and bias\n",
    "def update_parameters(x, y, y_hat, weights, bias, learning_rate=0.05):\n",
    "    \n",
    "    n = y.shape[0]\n",
    "    \n",
    "    error = y_hat - y\n",
    "    \n",
    "    dw = np.dot(x.T, error) / n\n",
    "    db = error.sum() / n\n",
    "    \n",
    "    weights -= dw * learning_rate\n",
    "    bias -= db * learning_rate\n",
    "\n",
    "# fit\n",
    "def train(x, y, iterations=200):\n",
    "    w = np.random.rand(x.shape[1],1)\n",
    "    b = np.ones((1,1))\n",
    "\n",
    "    for n in range(iterations):\n",
    "        y_hat = predict(x, w, b)\n",
    "        update_parameters(x, y, y_hat, w, b)\n",
    "        \n",
    "        if (n + 1) % 10 == 0:\n",
    "            print(\"%ith iteration error: %s\" % (n + 1, cross_entropy(y_hat, y)))\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10th iteration error: 1.005350216658127\n",
      "20th iteration error: 0.8928319155534907\n",
      "30th iteration error: 0.8096351078194921\n",
      "40th iteration error: 0.7486534603178534\n",
      "50th iteration error: 0.7036140870350333\n",
      "60th iteration error: 0.6696642738282635\n",
      "70th iteration error: 0.6433242044944267\n",
      "80th iteration error: 0.6221997433419623\n",
      "90th iteration error: 0.6046767816200218\n",
      "100th iteration error: 0.5896753480190486\n",
      "110th iteration error: 0.5764729403312535\n",
      "120th iteration error: 0.5645841057836171\n",
      "130th iteration error: 0.5536803312591946\n",
      "140th iteration error: 0.5435372575590268\n",
      "150th iteration error: 0.5339999577330564\n",
      "160th iteration error: 0.5249600431578945\n",
      "170th iteration error: 0.5163405023018077\n",
      "180th iteration error: 0.5080856088107867\n",
      "190th iteration error: 0.5001541689196971\n",
      "200th iteration error: 0.49251498094241797\n",
      "210th iteration error: 0.4851437684111809\n",
      "220th iteration error: 0.47802110011638166\n",
      "230th iteration error: 0.4711309741599912\n",
      "240th iteration error: 0.46445985055276473\n",
      "250th iteration error: 0.45799598779844297\n",
      "260th iteration error: 0.4517289860386653\n",
      "270th iteration error: 0.4456494708486788\n",
      "280th iteration error: 0.43974887296195675\n",
      "290th iteration error: 0.434019273510485\n",
      "300th iteration error: 0.42845329406566\n",
      "310th iteration error: 0.42304401735671837\n",
      "320th iteration error: 0.41778492903357756\n",
      "330th iteration error: 0.4126698739034659\n",
      "340th iteration error: 0.40769302216118297\n",
      "350th iteration error: 0.4028488425600758\n",
      "360th iteration error: 0.39813208044495774\n",
      "370th iteration error: 0.3935377392325654\n",
      "380th iteration error: 0.3890610643776845\n",
      "390th iteration error: 0.38469752917082045\n",
      "400th iteration error: 0.38044282192213186\n",
      "[[0.14268079]\n",
      " [0.28627429]\n",
      " [0.30554792]\n",
      " [0.5146547 ]]\n"
     ]
    }
   ],
   "source": [
    "w = np.random.rand(2,1)\n",
    "b = np.ones((1,1))\n",
    "x = np.array([[0, 0], [1, 0], [0, 1], [1, 1]])\n",
    "y = np.array([[0], [0], [0], [1]])\n",
    "\n",
    "w, b = train(x, y, 400)\n",
    "\n",
    "y_hat = predict(x, w, b)\n",
    "print(y_hat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
