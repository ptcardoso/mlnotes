{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.misc import imsave, imresize\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "from keras.applications import vgg16\n",
    "from keras import backend as K\n",
    "from tensorflow.contrib.keras.api.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "def load_image(filename, dims=(224, 224, 3)):\n",
    "    img = load_img(filename)\n",
    "    img = img_to_array(img)\n",
    "    img = imresize(img, dims)\n",
    "    img = img.astype('float64')\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = vgg16.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def restore_image(img, img_h=224, img_w=224):\n",
    "    img = img.reshape((img_h, img_w, 3))\n",
    "    # Remove zero-center by mean pixel\n",
    "    img[:, :, 0] += 103.939\n",
    "    img[:, :, 1] += 116.779\n",
    "    img[:, :, 2] += 123.68\n",
    "    # 'BGR'->'RGB'\n",
    "    img = img[:, :, ::-1]\n",
    "    img = np.clip(img, 0, 255).astype('uint8')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save image\n",
    "def save_image(image, filename):\n",
    "    image = np.clip(image, 0.0, 255.0)\n",
    "    image = image.astype(np.uint8)\n",
    "    \n",
    "    with open(filename, 'wb') as file:\n",
    "        PIL.Image.fromarray(image).save(file, 'jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss functions\n",
    "def mean_squared_error(a, b):\n",
    "    return K.mean(K.square(a - b))\n",
    "\n",
    "def gram_matrix(tensor, num_channels=3):\n",
    "    gram = K.dot(K.transpose(tensor), tensor)\n",
    "    return gram\n",
    "    \n",
    "def content_loss(model, content_layer_ids):\n",
    "    total_loss = 0\n",
    "    \n",
    "    for layer_id in content_layer_ids:\n",
    "        layer_features = model.get_layer(index=layer_id).output\n",
    "        \n",
    "        content_features = layer_features[0, :, :, :]\n",
    "        combination_features = layer_features[2, :, :, :]\n",
    "        \n",
    "        loss = mean_squared_error(content_features, combination_features)\n",
    "        \n",
    "        total_loss += loss\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "def style_loss(model, style_layer_ids):\n",
    "    total_loss = 0\n",
    "\n",
    "    for layer_id in style_layer_ids:\n",
    "        layer_features = model.get_layer(index=layer_id).output\n",
    "        \n",
    "        style_features = gram_matrix(layer_features[1, :, :, :])\n",
    "        combination_features = gram_matrix(layer_features[2, :, :, :])\n",
    "        \n",
    "        loss = mean_squared_error(style_features, combination_features)\n",
    "        \n",
    "        total_loss += loss\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "def denoise_loss(x):\n",
    "    loss = K.sum(K.abs(x[:,1:,:,:] - x[:,:-1,:,:])) + K.sum(K.abs(x[:,:,1:,:] - x[:,:,:-1,:]))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# style transfer\n",
    "def style_transfer(content_image, style_image, content_layer_ids, style_layer_ids, \n",
    "                   weight_content=1.5, weight_style=10.0, weight_denoise=0.3, num_iterations=120,\n",
    "                  step_size=10.0, dims=(224,224,3)):\n",
    "    \n",
    "    content_image = K.variable(content_image)\n",
    "    style_image = K.variable(style_image)\n",
    "    combination_image = K.placeholder(shape=(1, dims[0], dims[1], dims[2]))\n",
    "    \n",
    "    \n",
    "    input_tensor = K.concatenate([content_image, style_image, combination_image], axis=0)\n",
    "    \n",
    "    model = vgg16.VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
    "    \n",
    "        \n",
    "    content_loss_val = content_loss(model, content_layer_ids) \n",
    "    style_loss_val = style_loss(model, style_layer_ids)    \n",
    "    \n",
    "    loss_combined = weight_content * content_loss_val + weight_style * style_loss_val\n",
    "    \n",
    "    grads = K.gradients(loss_combined, combination_image)\n",
    "    \n",
    "    outputs = [loss_combined]\n",
    "    \n",
    "    if isinstance(grads, (list, tuple)):\n",
    "        outputs += grads\n",
    "    else:\n",
    "        outputs.append(grads)\n",
    "        \n",
    "    f_output = K.function([combination_image], outputs)\n",
    "\n",
    "    def get_loss(x, img_w=dims[0], img_h=dims[1]):\n",
    "        x = x.reshape((1, img_h, img_w, 3))\n",
    "        outs = f_output([x])\n",
    "        return outs[0]\n",
    "    \n",
    "    def get_grads(x, img_w=dims[0], img_h=dims[1]):\n",
    "        x = x.reshape((1, img_h, img_w, 3))\n",
    "        outs = f_output([x])\n",
    "        if len(outs[1:]) == 1:\n",
    "            grad_values = outs[1].flatten().astype('float64')\n",
    "        else:\n",
    "            grad_values = np.array(outs[1:]).flatten().astype('float64')\n",
    "        return grad_values\n",
    "    \n",
    "    return get_loss, get_grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pedrocardoso/.local/share/virtualenvs/mlnotes--cLpeW_k/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "content_filename = 'resources/willy_wonka_old.jpg'\n",
    "content_image = load_image(content_filename)\n",
    "style_filename = 'resources/style1.jpg'\n",
    "style_image = load_image(style_filename)\n",
    "content_layer_ids = [4]\n",
    "style_layer_ids = list(range(13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_loss, get_grads = style_transfer(content_image=content_image, style_image=style_image, \n",
    "               content_layer_ids=content_layer_ids, style_layer_ids=style_layer_ids)\n",
    "\n",
    "\n",
    "\n",
    "x, min_val, info = fmin_l_bfgs_b(get_loss, content_image.flatten(), fprime=get_grads, maxiter=1)\n",
    "print('loss: {}'.format(min_val))\n",
    "# Save img\n",
    "img = restore_image(x)\n",
    "imsave('/img{}.jpg'.format(1), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
